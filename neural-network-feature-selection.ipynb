{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hetarthchopra/neural-network-feature-selection?scriptVersionId=114404956\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-20T18:29:08.972204Z","iopub.execute_input":"2022-12-20T18:29:08.972752Z","iopub.status.idle":"2022-12-20T18:29:08.984825Z","shell.execute_reply.started":"2022-12-20T18:29:08.972713Z","shell.execute_reply":"2022-12-20T18:29:08.983814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook is just a code run through for the tutorial at https://captum.ai/tutorials/Titanic_Basic_Interpret. \nI have used it to get up to speed with Captum, PyTorch and Model Interpretability. \n\nApart from that, I will be building a model with all the features first, and then I will try to increase the accuracy after removin the less important features using Integrated Gradients Approach","metadata":{}},{"cell_type":"code","source":"!pip install captum","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:29:09.6547Z","iopub.execute_input":"2022-12-20T18:29:09.655415Z","iopub.status.idle":"2022-12-20T18:29:20.857263Z","shell.execute_reply.started":"2022-12-20T18:29:09.655374Z","shell.execute_reply":"2022-12-20T18:29:20.85544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\n\nfrom captum.attr import IntegratedGradients\nfrom captum.attr import LayerConductance\nfrom captum.attr import NeuronConductance\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n!matplotlib.inline\n\nfrom scipy import stats\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:29:20.860716Z","iopub.execute_input":"2022-12-20T18:29:20.861233Z","iopub.status.idle":"2022-12-20T18:29:21.963088Z","shell.execute_reply.started":"2022-12-20T18:29:20.861177Z","shell.execute_reply":"2022-12-20T18:29:21.961208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read the dataset\ntitanic_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n# do one hot encoding\ntitanic_data = pd.concat([titanic_data,\n                          pd.get_dummies(titanic_data['Sex']),\n                          pd.get_dummies(titanic_data['Embarked'],prefix=\"embark\"),\n                          pd.get_dummies(titanic_data['Pclass'],prefix=\"pclass\")], axis=1)\ntitanic_data[\"Age\"] = titanic_data[\"Age\"].fillna(titanic_data[\"Age\"].mean())\ntitanic_data[\"Fare\"] = titanic_data[\"Fare\"].fillna(titanic_data[\"Fare\"].mean())\ntitanic_data = titanic_data.drop(['Name','Ticket','Cabin','Sex','Embarked','Pclass','PassengerId'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:29:21.96558Z","iopub.execute_input":"2022-12-20T18:29:21.96613Z","iopub.status.idle":"2022-12-20T18:29:21.995827Z","shell.execute_reply.started":"2022-12-20T18:29:21.966077Z","shell.execute_reply":"2022-12-20T18:29:21.994518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:29:21.999285Z","iopub.execute_input":"2022-12-20T18:29:21.999815Z","iopub.status.idle":"2022-12-20T18:29:22.018418Z","shell.execute_reply.started":"2022-12-20T18:29:21.999767Z","shell.execute_reply":"2022-12-20T18:29:22.01719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#set random seed for reproducibility\nnp.random.seed(100)\n\n# convert all to numpy\nlabels = titanic_data['Survived'].to_numpy()\ntitanic_data = titanic_data.drop(['Survived'],axis=1)\nfeature_names = list(titanic_data.columns)\ndata = titanic_data.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:29:22.01998Z","iopub.execute_input":"2022-12-20T18:29:22.020345Z","iopub.status.idle":"2022-12-20T18:29:22.029667Z","shell.execute_reply.started":"2022-12-20T18:29:22.020314Z","shell.execute_reply":"2022-12-20T18:29:22.02815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# separate train and test data\ntrain_indices = np.random.choice(len(labels), int(0.7*len(labels)), replace=False)\ntest_indices = list(set(range(len(labels))) - set(train_indices))  \ntrain_features = data[train_indices]\ntrain_labels = labels[train_indices]\ntest_features = data[test_indices]\ntest_labels = labels[test_indices]","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:29:22.031412Z","iopub.execute_input":"2022-12-20T18:29:22.031983Z","iopub.status.idle":"2022-12-20T18:29:22.046797Z","shell.execute_reply.started":"2022-12-20T18:29:22.031945Z","shell.execute_reply":"2022-12-20T18:29:22.045573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, x,y):\n        super().__init__()\n        self.x = x\n        self.y = y \n    \n    def __getitem__(self,idx):\n        return self.x[idx], self.y[idx]\n    \n    def __len__(self):\n        return len(self.x)\n\n# define the train and test dataloader\ntrain_loader = torch.utils.data.DataLoader(Dataset(train_features,train_labels))\ntest_loader = torch.utils.data.DataLoader(Dataset(test_features,test_labels))","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:29:22.048809Z","iopub.execute_input":"2022-12-20T18:29:22.049971Z","iopub.status.idle":"2022-12-20T18:29:22.059266Z","shell.execute_reply.started":"2022-12-20T18:29:22.049928Z","shell.execute_reply":"2022-12-20T18:29:22.058062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build a Baseline Model","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(1)\n\n# code a neural network with the nn module imported into the class\nclass Titanic_Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = nn.Linear(12,12)\n        self.sigmoid1 = nn.Sigmoid()\n        self.linear2 = nn.Linear(12,8)\n        self.sigmoid2 = nn.Sigmoid()\n        self.linear3 = nn.Linear(8,2)\n        self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self,x):\n        lin1_out = self.linear1(x)\n        sigmoid1_out = self.sigmoid1(lin1_out)\n        lin2_out = self.linear2(sigmoid1_out)\n        sigmoid2_out = self.sigmoid2(lin2_out)\n        lin3_out = self.linear3(sigmoid2_out)\n        softmax_out = self.softmax(lin3_out)\n        return softmax_out","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:29:22.060727Z","iopub.execute_input":"2022-12-20T18:29:22.061096Z","iopub.status.idle":"2022-12-20T18:29:22.072886Z","shell.execute_reply.started":"2022-12-20T18:29:22.061062Z","shell.execute_reply":"2022-12-20T18:29:22.071968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Titanic_Model()\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ntotal_loss, total_acc = list(),list()\nfeat_imp = np.zeros(train_features.shape[1])\nnum_epochs = 200\n\nfor epoch in range(num_epochs):\n    losses = 0 \n    for idx, (x,y) in enumerate(train_loader):\n        x,y = x.float(), y.type(torch.LongTensor)\n        x.requires_grad=True\n        optimizer.zero_grad()\n        # check if the progrma can be run with model(x) and model.forward()\n        preds=model.forward(x)\n        loss=criterion(preds,y)\n        x.requires_grad = False\n        loss.backward()\n        optimizer.step()\n        losses+=loss.item()\n    total_loss.append(losses/len(train_loader))\n    if epoch%5==0:\n        print(\"Epoch:\", str(epoch+1), \"\\tLoss:\", total_loss[-1])","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:29:22.07424Z","iopub.execute_input":"2022-12-20T18:29:22.074562Z","iopub.status.idle":"2022-12-20T18:31:12.364275Z","shell.execute_reply.started":"2022-12-20T18:29:22.074533Z","shell.execute_reply":"2022-12-20T18:31:12.363168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the model\ntorch.save(model.state_dict(), '/kaggle/working/titanic_model.pt')","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:12.375706Z","iopub.execute_input":"2022-12-20T18:31:12.376429Z","iopub.status.idle":"2022-12-20T18:31:12.388508Z","shell.execute_reply.started":"2022-12-20T18:31:12.376382Z","shell.execute_reply":"2022-12-20T18:31:12.387322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ncorrect=0\nfor idx, (x,y) in enumerate(test_loader):\n    with torch.no_grad():\n        x,y = x.float(), y.type(torch.LongTensor)\n        pred = model(x)\n        preds_class = torch.argmax(pred)\n        if (preds_class.numpy()== y.numpy()[0]):\n            correct+=1\nprint(\"Accuracy = \", correct/len(test_indices))","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:12.390228Z","iopub.execute_input":"2022-12-20T18:31:12.39117Z","iopub.status.idle":"2022-12-20T18:31:12.451973Z","shell.execute_reply.started":"2022-12-20T18:31:12.391112Z","shell.execute_reply":"2022-12-20T18:31:12.450749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input_tensor = torch.from_numpy(test_features).type(torch.FloatTensor)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:12.460664Z","iopub.execute_input":"2022-12-20T18:31:12.461304Z","iopub.status.idle":"2022-12-20T18:31:12.472004Z","shell.execute_reply.started":"2022-12-20T18:31:12.461268Z","shell.execute_reply":"2022-12-20T18:31:12.470944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calculate the Integrated Gradients","metadata":{}},{"cell_type":"code","source":"ig = IntegratedGradients(model)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:12.473427Z","iopub.execute_input":"2022-12-20T18:31:12.47473Z","iopub.status.idle":"2022-12-20T18:31:12.484333Z","shell.execute_reply.started":"2022-12-20T18:31:12.474677Z","shell.execute_reply":"2022-12-20T18:31:12.483227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input_tensor.requires_grad_()\nattr, delta = ig.attribute(test_input_tensor, target = 1, return_convergence_delta  = True)\nattr = attr.detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:12.485981Z","iopub.execute_input":"2022-12-20T18:31:12.486344Z","iopub.status.idle":"2022-12-20T18:31:14.234006Z","shell.execute_reply.started":"2022-12-20T18:31:12.486312Z","shell.execute_reply":"2022-12-20T18:31:14.232718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper method to print importances and visualize distribution\ndef visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\"):\n    print(title)\n    for i in range(len(feature_names)):\n        print(feature_names[i], \": \", '%.3f'%(importances[i]))\n    x_pos = (np.arange(len(feature_names)))\n    if plot:\n        plt.figure(figsize=(12,6))\n        plt.bar(x_pos, importances, align='center')\n        plt.xticks(x_pos, feature_names, wrap=True)\n        plt.xlabel(axis_title)\n        plt.title(title)\nvisualize_importances(feature_names, np.mean(np.abs(attr), axis=0))","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:14.235612Z","iopub.execute_input":"2022-12-20T18:31:14.236738Z","iopub.status.idle":"2022-12-20T18:31:14.536764Z","shell.execute_reply.started":"2022-12-20T18:31:14.236691Z","shell.execute_reply":"2022-12-20T18:31:14.535392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get Top K Least Important Features","metadata":{}},{"cell_type":"code","source":"k_features=4\nfeatures_to_be_dropped = [b for (a,b) in sorted(zip(feat_imp,feature_names))][0:k_features]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make the New Dataset","metadata":{}},{"cell_type":"code","source":"# do not include variables such as Parch, Embark_C, Embark_Q,Embark_S and others that you feel, which have low feature importance\n# read the dataset\ntitanic_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n# do one hot encoding\ntitanic_data = pd.concat([titanic_data,\n                          pd.get_dummies(titanic_data['Sex']),\n                          pd.get_dummies(titanic_data['Pclass'],prefix=\"pclass\")], axis=1)\ntitanic_data[\"Age\"] = titanic_data[\"Age\"].fillna(titanic_data[\"Age\"].mean())\ntitanic_data[\"Fare\"] = titanic_data[\"Fare\"].fillna(titanic_data[\"Fare\"].mean())\ntitanic_data = titanic_data.drop(['Name','Ticket','Cabin','Sex','Embarked','Pclass','PassengerId','Parch'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:14.538312Z","iopub.execute_input":"2022-12-20T18:31:14.538785Z","iopub.status.idle":"2022-12-20T18:31:14.560578Z","shell.execute_reply.started":"2022-12-20T18:31:14.538748Z","shell.execute_reply":"2022-12-20T18:31:14.559586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert all to numpy\nlabels = titanic_data['Survived'].to_numpy()\ntitanic_data = titanic_data.drop(['Survived'],axis=1)\nfeature_names = list(titanic_data.columns)\ndata = titanic_data.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:14.562114Z","iopub.execute_input":"2022-12-20T18:31:14.562833Z","iopub.status.idle":"2022-12-20T18:31:14.571202Z","shell.execute_reply.started":"2022-12-20T18:31:14.562788Z","shell.execute_reply":"2022-12-20T18:31:14.569999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# separate train and test data\ntrain_indices = np.random.choice(len(labels), int(0.7*len(labels)), replace=False)\ntest_indices = list(set(range(len(labels))) - set(train_indices))\ntrain_features = data[train_indices]\ntrain_labels = labels[train_indices]\ntest_features = data[test_indices]\ntest_labels = labels[test_indices]","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:14.57297Z","iopub.execute_input":"2022-12-20T18:31:14.575095Z","iopub.status.idle":"2022-12-20T18:31:14.584547Z","shell.execute_reply.started":"2022-12-20T18:31:14.575049Z","shell.execute_reply":"2022-12-20T18:31:14.583545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the train and test dataloader\ntrain_loader = torch.utils.data.DataLoader(Dataset(train_features,train_labels))\ntest_loader = torch.utils.data.DataLoader(Dataset(test_features,test_labels))","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:14.585932Z","iopub.execute_input":"2022-12-20T18:31:14.586351Z","iopub.status.idle":"2022-12-20T18:31:14.598196Z","shell.execute_reply.started":"2022-12-20T18:31:14.586305Z","shell.execute_reply":"2022-12-20T18:31:14.596907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Retrain model with different dataset","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(1)\n\n# code a neural network with the nn module imported into the class\nclass Titanic_Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = nn.Linear(8,12) # since features have been dropped chaneg input layer\n        self.sigmoid1 = nn.Sigmoid()\n        self.linear2 = nn.Linear(12,8)\n        self.sigmoid2 = nn.Sigmoid()\n        self.linear3 = nn.Linear(8,2)\n        self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self,x):\n        lin1_out = self.linear1(x)\n        sigmoid1_out = self.sigmoid1(lin1_out)\n        lin2_out = self.linear2(sigmoid1_out)\n        sigmoid2_out = self.sigmoid2(lin2_out)\n        lin3_out = self.linear3(sigmoid2_out)\n        softmax_out = self.softmax(lin3_out)\n        return softmax_out","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:14.600159Z","iopub.execute_input":"2022-12-20T18:31:14.600577Z","iopub.status.idle":"2022-12-20T18:31:14.611595Z","shell.execute_reply.started":"2022-12-20T18:31:14.600533Z","shell.execute_reply":"2022-12-20T18:31:14.610296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Titanic_Model()\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ntotal_loss, total_acc = list(),list()\nfeat_imp = np.zeros(train_features.shape[1])\nnum_epochs = 200\n\nfor epoch in range(num_epochs):\n    losses = 0 \n    for idx, (x,y) in enumerate(train_loader):\n        x,y = x.float(), y.type(torch.LongTensor)\n        x.requires_grad=True\n        optimizer.zero_grad()\n        # check if the progrma can be run with model(x) and model.forward()\n        preds=model.forward(x)\n        loss=criterion(preds,y)\n        x.requires_grad = False\n        loss.backward()\n        optimizer.step()\n        losses+=loss.item()\n    total_loss.append(losses/len(train_loader))\n    if epoch%5==0:\n        print(\"Epoch:\", str(epoch+1), \"\\tLoss:\", total_loss[-1])","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:31:14.613201Z","iopub.execute_input":"2022-12-20T18:31:14.613557Z","iopub.status.idle":"2022-12-20T18:33:03.732752Z","shell.execute_reply.started":"2022-12-20T18:31:14.613526Z","shell.execute_reply":"2022-12-20T18:33:03.731493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ncorrect=0\nfor idx, (x,y) in enumerate(test_loader):\n    with torch.no_grad():\n        x,y = x.float(), y.type(torch.LongTensor)\n        pred = model(x)\n        preds_class = torch.argmax(pred)\n        if (preds_class.numpy()== y.numpy()[0]):\n            correct+=1\nprint(\"Accuracy = \", correct/len(test_indices))","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:33:03.734274Z","iopub.execute_input":"2022-12-20T18:33:03.734645Z","iopub.status.idle":"2022-12-20T18:33:03.795685Z","shell.execute_reply.started":"2022-12-20T18:33:03.734599Z","shell.execute_reply":"2022-12-20T18:33:03.794472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # # *We can see from here that the Test Accuracy increases as we use less features after feature selection.*","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}